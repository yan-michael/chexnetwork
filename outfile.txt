Training NN architecture =  DENSE-NET-121
/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  nn.init.kaiming_normal(m.weight.data)
/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
/home/ubuntu/chexnet/ChexnetTrainer.py:157: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  varInput = torch.autograd.Variable(input, volatile=True)
/home/ubuntu/chexnet/ChexnetTrainer.py:158: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  varTarget = torch.autograd.Variable(target, volatile=True)
Traceback (most recent call last):
  File "Main.py", line 83, in <module>
    main()
  File "Main.py", line 13, in main
    runTrain()
  File "Main.py", line 56, in runTrain
    ChexnetTrainer.train(pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, imgtransResize, imgtransCrop, timestampLaunch, None)
  File "/home/ubuntu/chexnet/ChexnetTrainer.py", line 98, in train
    lossVal, losstensor = ChexnetTrainer.epochVal (model, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss)
  File "/home/ubuntu/chexnet/ChexnetTrainer.py", line 159, in epochVal
    varOutput = model(varInput)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 141, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/chexnet/DensenetModels.py", line 27, in forward
    x = self.densenet121(x)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py", line 220, in forward
    features = self.features(x)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 76, in forward
    exponential_average_factor, self.eps)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 1623, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 6.12 MiB (GPU 0; 11.17 GiB total capacity; 10.74 GiB already allocated; 2.31 MiB free; 135.33 MiB cached)
